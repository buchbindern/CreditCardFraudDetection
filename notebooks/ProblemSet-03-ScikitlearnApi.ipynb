{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11d51098",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e712d6f",
   "metadata": {},
   "source": [
    "NAME = \"Natalie Buchbinder\"\n",
    "COLLABORATORS = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2f4537",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d6cb48",
   "metadata": {},
   "source": [
    "# Scikit-Learn\n",
    "\n",
    "This lab will test your knowledge of scikit-learn and your ability to perform basic tasks using this foundational library.\n",
    "\n",
    "You are welcome (and encouraged) to make use of the scikit-learn documention\n",
    "\n",
    "https://scikit-learn.org/stable/modules/classes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927b50c5",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n",
    "In this problem, we will implement a variety of sklearn estimators.\n",
    "\n",
    "## Part a)\n",
    "Implement a transformer which standardizes a dataset according to the following formula\n",
    "\n",
    "$$ X = \\frac{X - \\mu}{\\sigma}$$ Where $\\mu$ is the average and $\\sigma$ is the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "89c7106a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62a8886ef9c78ce807463d4e898f9697",
     "grade": false,
     "grade_id": "cell-b2723affb8d46bf3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
    "import pandas as pd\n",
    "from sklearn.utils.validation import check_X_y, check_array\n",
    "import numpy as np\n",
    "\n",
    "class StandardizerTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    # applies tranformation to feature matrix \n",
    "    def transform(self, x, y=''):\n",
    "        x = check_array(x)\n",
    "        if self.n_features_in_ != len(x[0]):\n",
    "            raise ValueError\n",
    "        x = (x-self.mean_) / self.std_    \n",
    "        \n",
    "        return x # return the transformed x (new data)\n",
    "    \n",
    "    # calculate the \"parameters\" or the mean and standard deviation:\n",
    "    def fit(self, x, y=''):\n",
    "        x, y = check_X_y(x, y)\n",
    "        self.n_features_in_ = len(x[0])\n",
    "        self.mean_ = np.mean(x)\n",
    "        self.std_ = np.std(x)\n",
    "     \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "33ce6cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "trial_df = [[1, 2, 3, 4, 2],\n",
    "[1,2,3,4,2],\n",
    "[0,0,0,0,0]]\n",
    "\n",
    "y = [1,2,3]\n",
    "\n",
    "trial_df\n",
    "\n",
    "\n",
    "st = StandardizerTransformer()\n",
    "model = st.fit(trial_df,y)\n",
    "print(model.mean_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c64db77f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69f49af97bf2cd08d06c6557ee1638ca",
     "grade": true,
     "grade_id": "cell-ce9193b5205876cb",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "check_estimator(StandardizerTransformer())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dde9e8",
   "metadata": {},
   "source": [
    "## Part b)\n",
    "\n",
    "Implement a Regressor which predicts the average of the input values.  As we know this is not a very good model, we will set the poor score tag so that we can validate the model interface. \n",
    "\n",
    "Please note that just because this is not the greatest model, that does not mean it is not a useful one.  This model can provide a wonderful baseline with which to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e4904b41",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63785440f3e34639ae5b35a8fcad0dff",
     "grade": false,
     "grade_id": "cell-633c278e6d0be1ce",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "\n",
    "class MeanModel(BaseEstimator, RegressorMixin):\n",
    "    def _more_tags(self):\n",
    "        return dict(poor_score=True)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.is_fitted_ = True\n",
    "        self.n_features_in_ = len(X[0])\n",
    "        self.mean_ = np.mean(X)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = check_array(X)\n",
    "        check_is_fitted(self)\n",
    "        return np.full(shape=X.shape[0], fill_value=self.mean_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "daac7ca8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5fe4796cd62a65310019201ceb63a80",
     "grade": true,
     "grade_id": "cell-3909c3c95082d781",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "check_estimator(MeanModel())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62494483",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "In this problem, we will explore some of the higher level constructs in sklearn.  Lets start by downloading the dataset from\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/2/adult\n",
    "\n",
    "which is known as the census income dataset (see `adult.names` after the downloading of the data for more info).  We can do this with the following python function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b4a6a1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/adult.data'),\n",
       " PosixPath('data/adult.names'),\n",
       " PosixPath('data/adult.test')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/{}\"\n",
    "def download(url, filepath):\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with filepath.open('wb') as fp:\n",
    "            for chunk in r.iter_content():\n",
    "                fp.write(chunk)\n",
    "        \n",
    "def download_adult_data(ignore_cache=False):\n",
    "    data_path = Path('data')\n",
    "    data_path.mkdir(exist_ok=True)\n",
    "    files = ['adult.data', 'adult.names', 'adult.test']\n",
    "    for file_ in files:\n",
    "        filepath = data_path.joinpath(file_)\n",
    "        if not ignore_cache and filepath.is_file():\n",
    "            continue\n",
    "        download(URL.format(file_), filepath)\n",
    "    return [data_path.joinpath(f) for f in files]\n",
    "download_adult_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfe77ea",
   "metadata": {},
   "source": [
    "Now we will load the data into appropriate datastructure  for processing with scikit-learn.  We use use `pandas` as a tool to import data.  Our goal is not to rewrite useful libraries but to use the tools available in order to do some interesting data stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4ab7b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "\n",
    "@dataclass\n",
    "class Dataset:\n",
    "    X_train: np.array\n",
    "    y_train: np.array\n",
    "    X_test: np.array\n",
    "    y_test: np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8aff33b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def load_adult_data():\n",
    "    download_adult_data()\n",
    "    data = pd.read_csv(Path('data').joinpath('adult.data'), header=None).values\n",
    "    test_data = pd.read_csv(Path('data').joinpath('adult.test'), header=None, skiprows=1).values\n",
    "    return Dataset(\n",
    "        X_train=data[:, :-1],\n",
    "        y_train=data[:, -1],\n",
    "        X_test=test_data[:, :-1],\n",
    "        y_test=np.array([i.rstrip('.') for i in test_data[:, -1]])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0519de8f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e69b8a0b0c91eafbb1f433831ea5e385",
     "grade": false,
     "grade_id": "cell-5c37ca7dc4a5f2a6",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Now lets do some exploratory data analysis on this dataset. In particular, look at the following columns \n",
    "\n",
    "- age\n",
    "- workclass\n",
    "- education\n",
    "\n",
    "\n",
    "And answer the following questions (with supporting evidence):\n",
    "\n",
    "- Is there anything about this feature which may need to be \"engineered\" in order to make it more useful?\n",
    "- Do you think that this feature has any predictive power?  Does this make intuitive sense to you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d856eaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age = 39 workclass =  State-gov education =  Bachelors\n",
      "age = 50 workclass =  Self-emp-not-inc education =  Bachelors\n",
      "age = 38 workclass =  Private education =  HS-grad\n",
      "age = 53 workclass =  Private education =  11th\n",
      "age = 28 workclass =  Private education =  Bachelors\n",
      "age = 37 workclass =  Private education =  Masters\n",
      "age = 49 workclass =  Private education =  9th\n",
      "age = 52 workclass =  Self-emp-not-inc education =  HS-grad\n",
      "age = 31 workclass =  Private education =  Masters\n",
      "age = 42 workclass =  Private education =  Bachelors\n",
      "Min Age: 17\n",
      "Max Age: 90\n",
      "\n",
      "Types of work: [' ?' ' Federal-gov' ' Local-gov' ' Never-worked' ' Private'\n",
      " ' Self-emp-inc' ' Self-emp-not-inc' ' State-gov' ' Without-pay']\n",
      "\n",
      "Types of education: [' 10th' ' 11th' ' 12th' ' 1st-4th' ' 5th-6th' ' 7th-8th' ' 9th'\n",
      " ' Assoc-acdm' ' Assoc-voc' ' Bachelors' ' Doctorate' ' HS-grad'\n",
      " ' Masters' ' Preschool' ' Prof-school' ' Some-college']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = load_adult_data()\n",
    "# age = 0, workclass = 1, education = 3. \n",
    "for i in range(10):\n",
    "    print(\"age =\", dataset.X_train[i][0], \n",
    "          \"workclass =\", dataset.X_train[i][1], \n",
    "          \"education =\", dataset.X_train[i][3])\n",
    "    \n",
    "print(\"Min Age:\", np.min(dataset.X_train[:,0]))\n",
    "print(\"Max Age:\", np.max(dataset.X_train[:,0]))\n",
    "\n",
    "print(\"\\nTypes of work:\", np.unique(dataset.X_train[:,1]))\n",
    "\n",
    "print(\"\\nTypes of education:\", np.unique(dataset.X_train[:,3]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d291bc89-5bc6-4785-bd40-d08d619d15e4",
   "metadata": {},
   "source": [
    "Is there anything about this feature which may need to be \"engineered\" in order to make it more useful?\n",
    "\n",
    "Yes, finding the min and max of each feature, how many times each instance occurs, average, etc\n",
    "\n",
    "Do you think that this feature has any predictive power? Does this make intuitive sense to you?\n",
    "\n",
    "It can. There may be correlations with age and education level or even workclass and education. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaab4f6",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "\n",
    "Now we will start to do some basic feature engineering and start building up a set of models.\n",
    "\n",
    "## Part a)\n",
    "\n",
    "First we will start with the education feature.  While education is a categorical variable in the dataset, we do not expect all categories to be completely orthognal.  Lets create a transformer which will take the education categories and collapse all education levels below HS-grad to a single value \"No-Degree\".  And yes, there is an education-number feature as well, however, we want to do some exercises to learn :)\n",
    "\n",
    "**NOTE**: Although coding standards and checking for correctness of transformations is important, we will be concerned here with only your output.  However, we will be testing edge cases, so make sure you are considering those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f8dc3422",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9423077567a44620b933ffd435756351",
     "grade": false,
     "grade_id": "cell-103eea76b61a5ba9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class EducationTransformer(BaseEstimator, TransformerMixin):\n",
    "  \n",
    "\n",
    "    def transform(self, x, y=''):\n",
    "\n",
    "        li = ['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th', '11th', '12th']\n",
    "                \n",
    "        for i in range(len(x)):\n",
    "            if x[i][0].strip() in li:\n",
    "                x[i][0] = \"No-Degree\"\n",
    "                    \n",
    "        return x\n",
    "        \n",
    "    def fit(self, x, y=''):\n",
    "        self.is_fitted_ = True\n",
    "        self.n_features_in_ = x.shape[0]\n",
    "        \n",
    "        return self\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "91b0bce6-b340-442b-8996-fb9e57321ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_adult_data()\n",
    "\n",
    "transformed = EducationTransformer().fit_transform(d.X_train[:, 3:4])[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "04ebbda9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "beadd678f71f3e7b78313a4a8bfca8d1",
     "grade": true,
     "grade_id": "cell-36abe3b1d7564f50",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "d = load_adult_data()\n",
    "\n",
    "transformed = EducationTransformer().fit_transform(d.X_train[:, 3:4])[:, 0]\n",
    "assert 'No-Degree' in set(transformed)\n",
    "assert '11th' not in set(transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e4bb7f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bachelors\n",
      " Bachelors\n",
      " HS-grad\n",
      "No-Degree\n",
      " Bachelors\n",
      " Masters\n",
      "No-Degree\n",
      " HS-grad\n",
      " Masters\n",
      " Bachelors\n",
      " Some-college\n",
      " Bachelors\n",
      " Bachelors\n",
      " Assoc-acdm\n",
      " Assoc-voc\n",
      "No-Degree\n",
      " HS-grad\n",
      " HS-grad\n",
      "No-Degree\n",
      " Masters\n",
      " Doctorate\n",
      " HS-grad\n",
      "No-Degree\n",
      "No-Degree\n",
      " HS-grad\n",
      " Bachelors\n",
      " HS-grad\n",
      " Some-college\n",
      " HS-grad\n",
      " HS-grad\n",
      " Assoc-acdm\n",
      " Some-college\n",
      " Bachelors\n",
      " Some-college\n",
      " Some-college\n",
      "No-Degree\n",
      " Some-college\n",
      " HS-grad\n",
      " Some-college\n",
      " Assoc-acdm\n",
      "No-Degree\n",
      " Bachelors\n",
      " Bachelors\n",
      " HS-grad\n",
      " HS-grad\n",
      " Bachelors\n",
      " HS-grad\n",
      " Masters\n",
      " Assoc-voc\n",
      " Assoc-voc\n",
      " Some-college\n",
      " HS-grad\n",
      " Prof-school\n",
      " Bachelors\n",
      " HS-grad\n",
      " Some-college\n",
      "No-Degree\n",
      " Assoc-voc\n",
      " HS-grad\n",
      " HS-grad\n",
      " Bachelors\n",
      "No-Degree\n",
      " HS-grad\n",
      " Doctorate\n",
      " Some-college\n",
      " HS-grad\n",
      " Some-college\n",
      " HS-grad\n",
      " Some-college\n",
      " Some-college\n",
      " Some-college\n",
      " Bachelors\n",
      " Bachelors\n",
      " Some-college\n",
      " Some-college\n",
      " HS-grad\n",
      " Assoc-acdm\n",
      "No-Degree\n",
      "No-Degree\n",
      "No-Degree\n",
      " HS-grad\n",
      " Bachelors\n",
      " HS-grad\n",
      " HS-grad\n",
      " HS-grad\n",
      " HS-grad\n",
      " HS-grad\n",
      " Masters\n",
      "No-Degree\n",
      " Doctorate\n",
      " Assoc-voc\n",
      " Some-college\n",
      " Some-college\n",
      " HS-grad\n",
      " Bachelors\n",
      " Some-college\n",
      " Doctorate\n",
      " Some-college\n",
      " Assoc-acdm\n",
      " HS-grad\n"
     ]
    }
   ],
   "source": [
    "#test that it works\n",
    "for i in range(100):\n",
    "    print(d.X_train[i][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5ffe05",
   "metadata": {},
   "source": [
    "## Part b)\n",
    "\n",
    "Now its often the case that models will not handle features which are not numerical, we will learn more about this later in class, however, for this specific example, we can get an intuition by thinking about these education levels.  Many algorithms (for example linear regression) will require that we use numerical features.  However, if we use numerical features, we are making some implicit assumptions about the metric on this data, specifically the distance between values.  Lets take a simple example with the following data\n",
    "\n",
    "|shirt_color|\n",
    "|---|\n",
    "|red|\n",
    "|red|\n",
    "|blue|\n",
    "|green|\n",
    "\n",
    "In this case, we could numerically encode this as \n",
    "\n",
    "\n",
    "|shirt_color|\n",
    "|---|\n",
    "|1|\n",
    "|1|\n",
    "|2|\n",
    "|3|\n",
    "\n",
    "and use a regression on the data, however, this would imply that red is somehow closer than to blue than to green.  In other words, our assignment of labels will affect the output.  Instead, we can reshape the matrix like so\n",
    "\n",
    "|shirt_color_red|shirt_color_blue|shirt_color_green|\n",
    "|---|---|---|\n",
    "|1|0|0|\n",
    "|1|0|0|\n",
    "|0|1|0|\n",
    "|0|0|1|\n",
    "\n",
    "which removes the encoding issues.\n",
    "\n",
    "Use the `OneHotcoder` from the sklearn library to build a more complex transformer which uses your previous transformer and then applies the one hot encoding on top of it.\n",
    "\n",
    "There are two possible ways to do this, one is to use a higher order constructor like a `Pipeline` and the other is to use composition.  You can do either in principle but please use a `Pipeline` to do it here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2972cc0a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a7fc5e151224093aadd4e25fd2c1d3f",
     "grade": false,
     "grade_id": "cell-3af3cf5a4a46f81f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "education_pipe = Pipeline([\n",
    "    (\"education\", EducationTransformer()), \n",
    "    \n",
    "    (\"one hot coder\", OneHotEncoder(handle_unknown='ignore'))\n",
    "    \n",
    "])\n",
    "\n",
    "#education_pipe.fit(d.X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c97a84f7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06681c090e60b8481d186b028f457d3a",
     "grade": true,
     "grade_id": "cell-4d88f6c40888206f",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "d = load_adult_data()\n",
    "\n",
    "transformed = education_pipe.fit_transform(d.X_train[:, 3:4])\n",
    "\n",
    "assert transformed.shape[0] == d.X_train.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d8f67a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 = [39 ' State-gov' 77516 ' Bachelors' 13 ' Never-married' ' Adm-clerical'\n",
      " ' Not-in-family' ' White' ' Male' 2174 0 40 ' United-States']\n",
      "1 = [50 ' Self-emp-not-inc' 83311 ' Bachelors' 13 ' Married-civ-spouse'\n",
      " ' Exec-managerial' ' Husband' ' White' ' Male' 0 0 13 ' United-States']\n",
      "2 = [38 ' Private' 215646 ' HS-grad' 9 ' Divorced' ' Handlers-cleaners'\n",
      " ' Not-in-family' ' White' ' Male' 0 0 40 ' United-States']\n",
      "3 = [53 ' Private' 234721 'No-Degree' 7 ' Married-civ-spouse'\n",
      " ' Handlers-cleaners' ' Husband' ' Black' ' Male' 0 0 40 ' United-States']\n",
      "4 = [28 ' Private' 338409 ' Bachelors' 13 ' Married-civ-spouse'\n",
      " ' Prof-specialty' ' Wife' ' Black' ' Female' 0 0 40 ' Cuba']\n",
      "5 = [37 ' Private' 284582 ' Masters' 14 ' Married-civ-spouse'\n",
      " ' Exec-managerial' ' Wife' ' White' ' Female' 0 0 40 ' United-States']\n",
      "6 = [49 ' Private' 160187 'No-Degree' 5 ' Married-spouse-absent'\n",
      " ' Other-service' ' Not-in-family' ' Black' ' Female' 0 0 16 ' Jamaica']\n",
      "7 = [52 ' Self-emp-not-inc' 209642 ' HS-grad' 9 ' Married-civ-spouse'\n",
      " ' Exec-managerial' ' Husband' ' White' ' Male' 0 0 45 ' United-States']\n",
      "8 = [31 ' Private' 45781 ' Masters' 14 ' Never-married' ' Prof-specialty'\n",
      " ' Not-in-family' ' White' ' Female' 14084 0 50 ' United-States']\n",
      "9 = [42 ' Private' 159449 ' Bachelors' 13 ' Married-civ-spouse'\n",
      " ' Exec-managerial' ' Husband' ' White' ' Male' 5178 0 40 ' United-States']\n"
     ]
    }
   ],
   "source": [
    "#education_pipe.fit(d.X_train)\n",
    "\n",
    "for i in range(10):\n",
    "    print(i, \"=\", d.X_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d66133",
   "metadata": {},
   "source": [
    "## Part c)\n",
    "\n",
    "Now we can apply our transformer to the feature matrix by making use of the scikit-learn object `ColumnTransformer`.  Use this to build a transformer which operates directly on the input feature matrix. Additionally, in order to make the auto grading work, please ensure the following:\n",
    "\n",
    "- Please name your solution transformer `ct_education`.  \n",
    "- Please make sure to pass through the rest of the columns. (check the `passthrough` options in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f00f3215",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d871d0c680c173f893d2acededc91f06",
     "grade": false,
     "grade_id": "cell-fd1313986df3f15d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct_education = ColumnTransformer(\n",
    "    [ ('EduOneHot', education_pipe, [3])],\n",
    "    remainder = 'passthrough' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a1f38757",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "37fc6c82c00a7c53e3a056df85ef7e99",
     "grade": true,
     "grade_id": "cell-40ba994f3191cc28",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "res = ct_education.fit_transform(d.X_train)\n",
    "\n",
    "assert res.shape[0] == d.X_train.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eae3a8c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9792f934edcfb212e0751fc3e0172f1d",
     "grade": false,
     "grade_id": "cell-24592c2305532eff",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Part d)\n",
    "\n",
    "Now fit a model using the following features:\n",
    "\n",
    "- your transformed education column\n",
    "- age\n",
    "- hours-per-week\n",
    "- capital-gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c92f5874-9389-4376-9a26-3bc8b00d685f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ' Bachelors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# your transformed education column\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# age : col 0\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# hours-per-week: col 12\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# capital-gain col 10\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/sklearn/linear_model/_base.py:678\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    674\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[1;32m    676\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 678\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    680\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/sklearn/base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/sklearn/utils/validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1144\u001b[0m     )\n\u001b[0;32m-> 1146\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/sklearn/utils/validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 915\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    919\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/sklearn/utils/_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: ' Bachelors'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(d.X_train[:, [0, 3, 10, 12]], d.y_train)\n",
    "\n",
    "\n",
    "# your transformed education column\n",
    "# age : col 0\n",
    "# hours-per-week: col 12\n",
    "# capital-gain col 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac73db05-03ec-45c8-b1fc-cab9424a2931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
